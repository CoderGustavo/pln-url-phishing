________________________________________
ğŸ•µï¸ Sherlock: DetecÃ§Ã£o de Phishing com Machine Learning
ğŸ“‹ Sobre o Projeto
Sherlock Ã© um modelo de aprendizado de mÃ¡quina desenvolvido para identificar URLs maliciosas, tambÃ©m conhecidas como phishing. O modelo analisa diversas caracterÃ­sticas das URLs, como o comprimento, a estrutura e a presenÃ§a de anormalidades, para prever se um link Ã© seguro ou suspeito.
________________________________________
ğŸ‘¥ Equipe
â€¢	Ester
â€¢	Gabriela
â€¢	Gustavo
â€¢	Mariana
________________________________________
ğŸ› ï¸ Tecnologias
â€¢	Linguagem: Python
â€¢	Bibliotecas: 
o	Pandas
o	NumPy
o	Scikit-learn
o	tld
o	re
o	urllib
o	joblib
________________________________________
ğŸ“Š Etapas do Projeto
1.	Carregamento e ExploraÃ§Ã£o dos Dados
O projeto utiliza um dataset com URLs classificadas como legÃ­timas ou maliciosas. O dataset contÃ©m 549.346 registros com 2 colunas principais: a URL e o rÃ³tulo (legÃ­tima ou maliciosa).
2.	PrÃ©-processamento dos Dados
o	Limpeza das URLs (remoÃ§Ã£o de padrÃµes como 'www.')
o	ExtraÃ§Ã£o de caracterÃ­sticas como comprimento da URL, presenÃ§a de IP, uso de HTTPS, etc.
o	CriaÃ§Ã£o de novas colunas para armazenar essas caracterÃ­sticas.
3.	Treinamento do Modelo
o	O modelo foi treinado utilizando o Random Forest Classifier.
o	A precisÃ£o do modelo foi avaliada e atingiu 79,04%.
4.	ClassificaÃ§Ã£o de URLs
o	A partir das caracterÃ­sticas extraÃ­das, o modelo pode prever se uma URL Ã© confiÃ¡vel ou nÃ£o.
o	O modelo foi validado utilizando URLs de exemplo e produziu previsÃµes precisas.
________________________________________
ğŸš€ Como Executar
1.	Instale as dependÃªncias:
Crie um ambiente virtual e instale as dependÃªncias necessÃ¡rias.
2.	pip install -r requirements.txt  
3.	PrÃ©-processamento e ExtraÃ§Ã£o de CaracterÃ­sticas:
Use o script preprocessing.py para processar os dados e gerar as caracterÃ­sticas necessÃ¡rias.
4.	Treinamento do Modelo:
Execute o script model.py para treinar o modelo utilizando o Random Forest Classifier.
5.	python src/model.py  
6.	Teste do Modelo:
Para testar o modelo com novas URLs, execute o script predict.py com o arquivo contendo as URLs de teste.
7.	python src/predict.py --input data/test_urls.csv  
________________________________________
ğŸ“ˆ Resultados
Treinamento e Teste do Modelo
â€¢	AcurÃ¡cia: O modelo obteve uma precisÃ£o de 79,04% no conjunto de teste, utilizando o algoritmo Random Forest Classifier.
PrevisÃ£o de Classe de URL
â€¢	Exemplo de URL: "super1000.info/docs"
â€¢	CaracterÃ­sticas extraÃ­das:
o	Comprimento da URL: 19
o	Contagem de letras: 13
o	Contagem de dÃ­gitos: 4
o	Contagem de caracteres especiais: 1
o	URL encurtada: NÃ£o
o	URL anormal: NÃ£o
o	HTTPS: NÃ£o
o	IP na URL: NÃ£o
o	IndexaÃ§Ã£o no Google: Sim
â€¢	Resultado da PrevisÃ£o:
o	CUIDADO! Link suspeito
Modelo Salvo
O modelo treinado foi salvo como um arquivo joblib chamado modelo_treinado_joblib.sav. Esse arquivo pode ser carregado em futuras implementaÃ§Ãµes para realizar previsÃµes em novos dados.
________________________________________
ğŸ“‚ Estrutura do Projeto
sherlock/  
â”‚  
â”œâ”€â”€ data/                # Dados brutos e processados  
â”œâ”€â”€ notebooks/           # Notebooks de anÃ¡lise  
â”œâ”€â”€ src/                 # CÃ³digo-fonte  
â”œâ”€â”€ README.md            # DocumentaÃ§Ã£o do projeto  
â”œâ”€â”€ requirements.txt     # Lista de bibliotecas necessÃ¡rias  
â””â”€â”€ .gitignore           # Arquivos ignorados pelo Git  
________________________________________
ğŸ“ Trabalho AcadÃªmico
Este trabalho foi desenvolvido como parte da disciplina Processamento de Linguagem Natural, ministrada pelo Professor Mateus Fuini, no curso Desenvolvimento de Software e Multiplataforma, da FATEC Itapira.
________________________________________

